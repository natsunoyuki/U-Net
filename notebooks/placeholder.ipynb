{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Example of a simple U-Net architecture (you can replace it with a more advanced model if needed)\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(64, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Custom Dataset to handle images and masks\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx]\n",
    "        mask = self.y[idx]\n",
    "        \n",
    "        # If you need to apply transformations (like resizing, normalization, etc.)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Ensure the mask is the right shape (e.g., single channel)\n",
    "        mask = torch.tensor(mask, dtype=torch.long)\n",
    "        \n",
    "        return image, mask\n",
    "\n",
    "# Function to train the model\n",
    "def train_segmentation_model(X, y, epochs=10, batch_size=8, learning_rate=1e-4, device='cuda'):\n",
    "    # Set the device\n",
    "    device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((256, 256)),  # Resize all images to 256x256 for simplicity\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    # Create dataset and dataloaders\n",
    "    dataset = SegmentationDataset(X, y, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Initialize model, loss function, and optimizer\n",
    "    model = UNet(in_channels=3, out_channels=2).to(device)  # 3 channels for RGB and 2 classes\n",
    "    criterion = nn.CrossEntropyLoss()  # Cross entropy loss for segmentation\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Iterate over the data\n",
    "        for images, masks in tqdm(dataloader, desc=f'Epoch {epoch+1}/{epochs}'):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Print loss for the epoch\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(dataloader)}\")\n",
    "    \n",
    "    print(\"Training finished!\")\n",
    "    return model\n",
    "\n",
    "# Example usage:\n",
    "# Assuming X and y are your images and segmentation masks\n",
    "# X = [image1, image2, ...]  # Each image is a numpy array of shape (C, H, W)\n",
    "# y = [mask1, mask2, ...]    # Each mask is a numpy array of shape (H, W)\n",
    "\n",
    "# Train the model\n",
    "trained_model = train_segmentation_model(X, y, epochs=5, batch_size=4, learning_rate=1e-4, device='cuda')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

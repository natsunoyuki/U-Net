{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "\n",
    "from unet.unet_model import UNet\n",
    "from unet.unet_dataset.image_and_masks.image_masks import ImageMasksDataset\n",
    "from unet.train_unet_utils import collate_fn, train\n",
    "\n",
    "from unet.train_unet_utils import unbatch, train_batch, validate_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "    \"device\": \"mps\",\n",
    "    \"in_channels\": 3,\n",
    "    \"out_channels\": 1,\n",
    "    \"conv_channels\": [8, 16, 32],\n",
    "    \"data_dir\": \"../data/water_bodies_segmentation/\",\n",
    "    \"train_image_folder\": \"train_images\",\n",
    "    \"train_mask_folder\": \"train_masks\",\n",
    "    \"test_image_folder\": \"test_images\",\n",
    "    \"test_mask_folder\": \"test_masks\",\n",
    "    \"batch_size\": 4,\n",
    "    \"epochs\": 20,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps.\n"
     ]
    }
   ],
   "source": [
    "# Device.\n",
    "device = configs.get(\n",
    "    \"device\", \n",
    "    torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")\n",
    "if torch.cuda.is_available() is False and device == torch.device(\"cuda\"):\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Using device: {}.\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U-Net in_channels=3, out_channels=1, conv_channels=[8, 16, 32].\n"
     ]
    }
   ],
   "source": [
    "# U-Net.\n",
    "in_channels = configs.get(\"in_channels\", 3)\n",
    "out_channels = configs.get(\"out_channels\", 1)\n",
    "conv_channels = configs.get(\"conv_channels\", [64, 128, 256, 512, 1024])\n",
    "\n",
    "model = UNet(in_channels, out_channels, conv_channels)\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "print(\"U-Net in_channels={}, out_channels={}, conv_channels={}.\".format(\n",
    "    in_channels, out_channels, conv_channels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 68\n"
     ]
    }
   ],
   "source": [
    "# Dataloaders.\n",
    "data_dir = configs.get(\"data_dir\", None)\n",
    "train_image_folder = configs.get(\"train_image_folder\", \"train_images\")\n",
    "train_mask_folder = configs.get(\"train_mask_folder\", \"train_masks\")\n",
    "test_image_folder = configs.get(\"test_image_folder\", \"test_images\")\n",
    "test_mask_folder = configs.get(\"test_mask_folder\", \"test_masks\")\n",
    "\n",
    "data_dir = Path(data_dir)\n",
    "\n",
    "# Train dataset. \n",
    "train_ds = ImageMasksDataset(\n",
    "    data_dir=data_dir, image_folder=train_image_folder, mask_folder=train_mask_folder, train=True\n",
    ")\n",
    "# Test dataset.\n",
    "test_ds = ImageMasksDataset(\n",
    "    data_dir=data_dir, image_folder=test_image_folder, mask_folder=test_mask_folder, train=False\n",
    ")\n",
    "\n",
    "print(len(train_ds), len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 17\n"
     ]
    }
   ],
   "source": [
    "# Create the DataLoaders from the Datasets. \n",
    "batch_size = configs.get(\"batch_size\", 4)\n",
    "n_epochs = configs.get(\"epochs\", 25)\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "    train_ds, batch_size = batch_size, shuffle = False, collate_fn = collate_fn,\n",
    ")\n",
    "\n",
    "test_dl = torch.utils.data.DataLoader(\n",
    "    test_ds, batch_size = batch_size, shuffle = False, collate_fn = collate_fn,\n",
    ")\n",
    "\n",
    "print(len(train_dl), len(test_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCELoss()\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.0005\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Set up optimizer and loss function.\n",
    "loss_function = torch.nn.BCELoss()\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "\n",
    "print(loss_function) \n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ###########################################################################\n",
      "Testing  #################\n",
      "Epoch 0. Train loss: 0.42278608679771423. Test loss: 0.2297869622707367.\n",
      "Training ###########################################################################\n",
      "Testing  #################\n",
      "Epoch 1. Train loss: 0.20809845626354218. Test loss: 0.1546270102262497.\n",
      "Training ###########################################################################\n",
      "Testing  #################\n",
      "Epoch 2. Train loss: 0.16863712668418884. Test loss: 0.1314755529165268.\n",
      "Training ###########################################################################\n",
      "Testing  #################\n",
      "Epoch 3. Train loss: 0.1520172506570816. Test loss: 0.11981411278247833.\n",
      "Training #######################################################################"
     ]
    }
   ],
   "source": [
    "# Train the model.\n",
    "model, train_losses, test_losses = train(model, optimizer, loss_function, n_epochs, train_dl, test_dl, device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Save the model to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\"\"\"\"\n",
    "for batch in test_dl:\n",
    "    break\n",
    "    \n",
    "model.eval()\n",
    "y_pred = model(batch[0].to(device))\n",
    "\n",
    "ys = batch[1]\n",
    "\n",
    "for i in range(4):\n",
    "    plt.figure()\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(y_pred[i].detach().cpu().numpy().squeeze())\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(ys[i].detach().cpu().numpy().squeeze())\n",
    "    plt.show()\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

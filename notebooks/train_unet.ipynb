{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchmetrics\n",
    "\n",
    "from unet.unet_model import UNet\n",
    "from unet.unet_dataset.image_and_masks.image_masks import ImageMasksDataset\n",
    "from unet.train_unet_utils import collate_fn, train\n",
    "from unet.loss_functions.focal_loss import FocalLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "    \"device\": \"mps\",\n",
    "    \"image_size\": [256, 256],\n",
    "    \"in_channels\": 3,\n",
    "    \"out_channels\": 1,\n",
    "    \"conv_channels\": [4, 8, 16],\n",
    "    \"data_dir\": \"../data/forest_segmentation/\",\n",
    "    \"train_image_folder\": \"train_images\",\n",
    "    \"train_mask_folder\": \"train_masks\",\n",
    "    \"test_image_folder\": \"test_images\",\n",
    "    \"test_mask_folder\": \"test_masks\",\n",
    "    \"batch_size\": 16,\n",
    "    \"epochs\": 10,\n",
    "    \"verbose\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device.\n",
    "device = configs.get(\n",
    "    \"device\", \n",
    "    torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")\n",
    "if torch.cuda.is_available() is False and device == torch.device(\"cuda\"):\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "verbose = configs.get(\"verbose\", False)\n",
    "if verbose is True:\n",
    "    print(\"Using device: {}.\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net.\n",
    "in_channels = configs.get(\"in_channels\", 3)\n",
    "out_channels = configs.get(\"out_channels\", 1)\n",
    "conv_channels = configs.get(\"conv_channels\", [8, 16, 32])\n",
    "\n",
    "model = UNet(in_channels, out_channels, conv_channels, up_conv_by_resampling=False)\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "if verbose is True:\n",
    "    print(\"U-Net in_channels={}, out_channels={}, conv_channels={}.\".format(\n",
    "        in_channels, out_channels, conv_channels)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders.\n",
    "data_dir = configs.get(\"data_dir\", None)\n",
    "train_image_folder = configs.get(\"train_image_folder\", \"train_images\")\n",
    "train_mask_folder = configs.get(\"train_mask_folder\", \"train_masks\")\n",
    "test_image_folder = configs.get(\"test_image_folder\", \"test_images\")\n",
    "test_mask_folder = configs.get(\"test_mask_folder\", \"test_masks\")\n",
    "\n",
    "image_size = configs.get(\"image_size\", None)\n",
    "\n",
    "data_dir = Path(data_dir)\n",
    "\n",
    "# Train dataset. \n",
    "train_ds = ImageMasksDataset(\n",
    "    data_dir=data_dir, \n",
    "    image_folder=train_image_folder, \n",
    "    mask_folder=train_mask_folder, \n",
    "    train=True,\n",
    "    image_size=image_size,\n",
    ")\n",
    "# Test dataset.\n",
    "test_ds = ImageMasksDataset(\n",
    "    data_dir=data_dir, \n",
    "    image_folder=test_image_folder, \n",
    "    mask_folder=test_mask_folder, \n",
    "    train=False,\n",
    "    image_size=image_size,\n",
    ")\n",
    "\n",
    "if verbose is True:\n",
    "    print(\"len(train_ds): {}, len(test_ds): {}.\".format(\n",
    "        len(train_ds), len(test_ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "img_mask = train_ds[idx]\n",
    "plt.subplot(1, 2, 1); plt.imshow(img_mask[0].permute(1, 2, 0).numpy())\n",
    "plt.subplot(1, 2, 2); plt.imshow(img_mask[1].permute(1, 2, 0).numpy(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataLoaders from the Datasets. \n",
    "batch_size = configs.get(\"batch_size\", 4)\n",
    "n_epochs = configs.get(\"epochs\", 25)\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "    train_ds, \n",
    "    batch_size = batch_size, \n",
    "    shuffle = True, \n",
    "    collate_fn = collate_fn,\n",
    ")\n",
    "\n",
    "test_dl = torch.utils.data.DataLoader(\n",
    "    test_ds, \n",
    "    batch_size = batch_size, \n",
    "    shuffle = False, \n",
    "    collate_fn = collate_fn,\n",
    ")\n",
    "\n",
    "if verbose is True:\n",
    "    print(\"Batch size: {}, train epochs: {}.\".format(batch_size, n_epochs))\n",
    "    print(\"len(train_dl): {}, len(test_dl): {}.\".format(\n",
    "        len(train_dl), len(test_dl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up optimizer and loss function.\n",
    "loss_function = torch.nn.BCELoss()\n",
    "#loss_function = FocalLoss(alpha=0.25, gamma=2)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(\n",
    "    params, \n",
    "    lr=0.001, \n",
    "    betas=(0.9, 0.999), \n",
    "    eps=1e-08, \n",
    "    weight_decay=0,\n",
    ")\n",
    "accuracy_metrics = [\n",
    "    torchmetrics.JaccardIndex(task=\"binary\"),\n",
    "]\n",
    "\n",
    "if verbose is True:\n",
    "    print(loss_function) \n",
    "    print(optimizer)\n",
    "    print(accuracy_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model.\n",
    "model, train_losses, test_losses, train_accuracies, test_accuracies = train(\n",
    "    model=model, \n",
    "    optimizer=optimizer, \n",
    "    loss_function=loss_function, \n",
    "    n_epochs=n_epochs, \n",
    "    train_loader=train_dl, \n",
    "    test_loader=test_dl, \n",
    "    device=device, \n",
    "    verbose=verbose,\n",
    "    metrics=accuracy_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    epochs = range(1, 1+len(train_losses))\n",
    "    plt.figure(figsize = [15, 5])\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, epochs, test_losses)\n",
    "    plt.legend([\"Train loss\", \"Test loss\"])\n",
    "    plt.grid(True); plt.xlabel(\"Epoch\"); plt.xticks(epochs); plt.ylabel(\"Loss\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_accuracies[:, 0], epochs, test_accuracies[:, 0])\n",
    "    plt.legend([\"Train accuracy\", \"Test accuracy\"])\n",
    "    plt.grid(True); plt.xlabel(\"Epoch\"); plt.xticks(epochs); plt.ylabel(\"Accuracy\")\n",
    "    plt.show()\n",
    "except:\n",
    "    print(\"An error occured during model training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some example predictions on the test set.\n",
    "N = 5\n",
    "\n",
    "model.eval()\n",
    "model.cpu()\n",
    "\n",
    "plt.figure(figsize = [5, 10])\n",
    "for i in range(N):\n",
    "    img_mask = test_ds[i]\n",
    "    img = img_mask[0]\n",
    "    mask = img_mask[1]\n",
    "    pred = model(img.unsqueeze(0)).detach().cpu().squeeze().round()\n",
    "    plt.subplot(N, 3, i*3+1); plt.imshow(img.permute(1, 2, 0).numpy()); plt.axis(False)\n",
    "    plt.subplot(N, 3, i*3+2); plt.imshow(mask.permute(1, 2, 0).numpy()); plt.axis(False)\n",
    "    plt.subplot(N, 3, i*3+3); plt.imshow(pred); plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Save the model to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "for batch in test_dl:\n",
    "    break\n",
    "    \n",
    "model.eval()\n",
    "y_pred = model(batch[0].to(device))\n",
    "\n",
    "ys = batch[1]\n",
    "\n",
    "for i in range(4):\n",
    "    plt.figure()\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(y_pred[i].detach().cpu().numpy().squeeze())\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(ys[i].detach().cpu().numpy().squeeze())\n",
    "    plt.show()\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
